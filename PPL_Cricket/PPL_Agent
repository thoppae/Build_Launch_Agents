{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnrCS7XefyVY9Ty96OyHwD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thoppae/Agent/blob/main/A1_PPL_Cricket_Launch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoPY53MwqnOq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import streamlit as st\n",
        "import csv\n",
        "from dotenv import load_dotenv\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.documents import Document\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "\n",
        "# --- The Fix: Apply nest_asyncio patch ---\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "# --- End of Fix ---\n",
        "\n",
        "# --- 1. Configuration and Setup ---\n",
        "load_dotenv()\n",
        "API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
        "\n",
        "st.set_page_config(page_title=\"Palkar Premier League Q&A\", layout=\"wide\")\n",
        "st.title(\"Palkar Premier League Q&A Bot 🏏\")\n",
        "\n",
        "if not API_KEY:\n",
        "    st.error(\"🚨 Google API Key not found. Please set the GOOGLE_API_KEY in your .env file.\")\n",
        "    st.stop()\n",
        "\n",
        "\n",
        "# --- 2. Core LangChain and Model Initialization ---\n",
        "@st.cache_resource\n",
        "def get_models():\n",
        "    \"\"\"Initializes and returns the LLM and embeddings model.\"\"\"\n",
        "    llm = ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-1.5-flash\",\n",
        "        google_api_key=API_KEY,\n",
        "        temperature=0.2,\n",
        "        convert_system_message_to_human=True\n",
        "    )\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(\n",
        "        model=\"models/embedding-001\",\n",
        "        google_api_key=API_KEY\n",
        "    )\n",
        "    return llm, embeddings\n",
        "\n",
        "\n",
        "llm, embeddings = get_models()\n",
        "\n",
        "\n",
        "# --- Helper function for cleaning CSV data ---\n",
        "def _clean_csv_dict(row: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Cleans the keys of a dictionary read from a CSV.\n",
        "    It strips whitespace and quote characters from each key.\n",
        "    \"\"\"\n",
        "    cleaned_dict = {}\n",
        "    for key, value in row.items():\n",
        "        if key:  # Ensure key is not None\n",
        "            cleaned_key = key.strip().strip('\"')\n",
        "            cleaned_dict[cleaned_key] = value\n",
        "    return cleaned_dict\n",
        "\n",
        "\n",
        "# --- 3. Data Loading and Vector Database Creation (for Q&A) ---\n",
        "@st.cache_resource\n",
        "def create_combined_vectordb(data_path: str, rules_path: str, _embeddings):\n",
        "    \"\"\"\n",
        "    Loads data for the RAG Q&A system. It creates a main summary document for each player,\n",
        "    plus additional, focused \"expert\" documents for important attributes like committee\n",
        "    roles and injuries to improve retrieval accuracy.\n",
        "    \"\"\"\n",
        "    player_docs = []\n",
        "    with open(data_path, mode='r', encoding='utf-8-sig') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        for i, row in enumerate(reader):\n",
        "            cleaned_row = _clean_csv_dict(row)\n",
        "            player_name = cleaned_row.get(\"Player Name\", \"Unknown Player\")\n",
        "\n",
        "            # --- Create the main, comprehensive document for each player ---\n",
        "            main_content = \"\"\n",
        "            for key, value in cleaned_row.items():\n",
        "                if value and value.strip():\n",
        "                    main_content += f\"{key}: {value.strip()}. \"\n",
        "\n",
        "            if main_content:\n",
        "                metadata = {\"source\": data_path, \"row\": i + 2, \"content_type\": \"Player Summary\"}\n",
        "                player_docs.append(Document(page_content=main_content.strip(), metadata=metadata))\n",
        "\n",
        "            # --- IMPROVEMENT: Create additional, focused documents for key attributes ---\n",
        "\n",
        "            # Create a dedicated document for Committee information\n",
        "            committee = cleaned_row.get(\"Committee\")\n",
        "            committee_task = cleaned_row.get(\"Committee Task\")\n",
        "            if committee and committee.strip():\n",
        "                committee_content = f\"Regarding player {player_name}: They are on the {committee} committee. The task is described as: {committee_task}\"\n",
        "                metadata = {\"source\": data_path, \"row\": i + 2, \"content_type\": \"Committee Role\"}\n",
        "                player_docs.append(Document(page_content=committee_content, metadata=metadata))\n",
        "\n",
        "            # Create a dedicated document for Injury information\n",
        "            injury_status = cleaned_row.get(\"Injury\")\n",
        "            if injury_status and injury_status.strip().lower() == 'yes':\n",
        "                injury_type = cleaned_row.get(\"Injury Type\", \"not specified\")\n",
        "                injury_desc = cleaned_row.get(\"Injury Description\", \"no description\")\n",
        "                injury_content = f\"Regarding player {player_name}: They have an injury. Status: {injury_status}. Type: {injury_type}. Description: {injury_desc}.\"\n",
        "                metadata = {\"source\": data_path, \"row\": i + 2, \"content_type\": \"Injury Status\"}\n",
        "                player_docs.append(Document(page_content=injury_content, metadata=metadata))\n",
        "\n",
        "    # --- Process Rule Data (as before) ---\n",
        "    rules_docs = []\n",
        "    with open(rules_path, mode='r', encoding='utf-8-sig') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        for i, row in enumerate(reader):\n",
        "            rule_text = row.get('Team Selection Rules')\n",
        "            if rule_text:\n",
        "                metadata = {\"source\": rules_path, \"row\": i + 2, \"content_type\": \"Rule\"}\n",
        "                rules_docs.append(Document(page_content=rule_text, metadata=metadata))\n",
        "\n",
        "    all_docs = player_docs + rules_docs\n",
        "    st.info(f\"Creating vector database for Q&A from {len(all_docs)} total documents (including focused experts)...\")\n",
        "    vectordb = FAISS.from_documents(documents=all_docs, embedding=_embeddings)\n",
        "    st.success(\"Q&A Vector database created successfully!\")\n",
        "    return vectordb\n",
        "\n",
        "\n",
        "vectordb = create_combined_vectordb(\n",
        "    data_path='data.csv',\n",
        "    rules_path='rules.csv',\n",
        "    _embeddings=embeddings\n",
        ")\n",
        "\n",
        "\n",
        "# --- 4. System Creation (Q&A Chain and Team Formation Helpers) ---\n",
        "def get_qa_chain(db, _llm):\n",
        "    \"\"\"Builds the simple RetrievalQA chain for factual questions.\"\"\"\n",
        "    prompt_template = \"\"\"\n",
        "    You are an assistant for the Palkar Premier League.\n",
        "    Use the following pieces of context to answer the question at the end.\n",
        "    If the answer is not found in the context, state \"I don't have enough information to answer that.\"\n",
        "    CONTEXT: {context}\n",
        "    QUESTION: {question}\n",
        "    HELPFUL ANSWER:\"\"\"\n",
        "    PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "    chain = RetrievalQA.from_chain_type(\n",
        "        llm=_llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 8}),\n",
        "        return_source_documents=True,\n",
        "        chain_type_kwargs={\"prompt\": PROMPT}\n",
        "    )\n",
        "    return chain\n",
        "\n",
        "\n",
        "def get_full_context_from_files(data_path: str, rules_path: str) -> (str, str):\n",
        "    \"\"\"Reads the raw CSV data and formats it as a string for the LLM.\"\"\"\n",
        "    with open(rules_path, mode='r', encoding='utf-8-sig') as f:\n",
        "        rules_text = f.read()\n",
        "\n",
        "    players_text = \"\"\n",
        "    with open(data_path, mode='r', encoding='utf-8-sig') as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            cleaned_row = _clean_csv_dict(row)\n",
        "            players_text += str(cleaned_row) + \"\\n\"\n",
        "\n",
        "    return rules_text, players_text\n",
        "\n",
        "\n",
        "qa_chain = get_qa_chain(vectordb, llm)\n",
        "\n",
        "# --- 5. Streamlit User Interface ---\n",
        "st.subheader(\"Ask a Factual Question\")\n",
        "st.write(\"Use this for simple questions about players or rules. For example: *'Who are the wicket keepers?'*\")\n",
        "\n",
        "with st.form(\"qa_form\"):\n",
        "    question = st.text_input(\"Your Question:\", key=\"question_input\")\n",
        "    submit_qa_button = st.form_submit_button(\"Ask\")\n",
        "\n",
        "if submit_qa_button and question:\n",
        "    with st.spinner(\"Searching for an answer...\"):\n",
        "        try:\n",
        "            response = qa_chain.invoke(question)\n",
        "            st.write(response['result'])\n",
        "            with st.expander(\"Show Sources\"):\n",
        "                st.write(\"The answer was generated from the following sources:\")\n",
        "                for doc in response['source_documents']:\n",
        "                    st.info(\n",
        "                        f\"Source: {doc.metadata.get('source', 'N/A')}, Row: {doc.metadata.get('row', 'N/A')}, Type: {doc.metadata.get('content_type', 'N/A')}\")\n",
        "                    st.text(doc.page_content)\n",
        "        except Exception as e:\n",
        "            st.error(f\"An error occurred: {e}\")\n",
        "\n",
        "st.divider()\n",
        "\n",
        "st.subheader(\"Form Balanced Teams (Advanced Reasoning)\")\n",
        "st.write(\"Use this to ask the AI to perform the complex task of creating teams based on all rules and players.\")\n",
        "\n",
        "num_teams = st.number_input(\"How many teams to form?\", min_value=1, max_value=10, value=1, step=1)\n",
        "\n",
        "if st.button(\"Generate Teams\"):\n",
        "    with st.spinner(f\"Performing complex reasoning to form {num_teams} teams. This may take a moment...\"):\n",
        "        try:\n",
        "            rules_context, players_context = get_full_context_from_files(\n",
        "                data_path='data.csv',\n",
        "                rules_path='rules.csv'\n",
        "            )\n",
        "\n",
        "            team_formation_prompt = f\"\"\"\n",
        "            You are a world-class expert in cricket team selection and logical reasoning. Your task is to create {num_teams} balanced teams from a list of players, strictly following a given set of rules.\n",
        "\n",
        "            **HERE ARE THE TEAM SELECTION RULES (You MUST follow all of them):**\n",
        "            ---\n",
        "            {rules_context}\n",
        "            ---\n",
        "\n",
        "            **HERE IS THE COMPLETE LIST OF AVAILABLE PLAYERS (in dictionary format with cleaned keys):**\n",
        "            ---\n",
        "            {players_context}\n",
        "            ---\n",
        "\n",
        "            **YOUR TASK:**\n",
        "            1.  **Analyze all rules and players thoroughly.**\n",
        "            2.  **Create exactly {num_teams} teams.** Distribute the players as evenly as possible.\n",
        "            3.  **Ensure every team composition satisfies ALL the rules.** For example, check the wicket keeper count, spinner types, injury limits, etc., for EACH team.\n",
        "            4.  **Provide a step-by-step thought process** explaining how you are forming the teams and verifying the rules.\n",
        "            5.  **Finally, present the final teams clearly.** List the player names for each team.\n",
        "\n",
        "            Begin your reasoning now.\n",
        "            \"\"\"\n",
        "\n",
        "            response = llm.invoke(team_formation_prompt)\n",
        "            st.write(response.content)\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"An error occurred during team formation: {e}\")"
      ]
    }
  ]
}
